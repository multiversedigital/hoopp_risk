"""
tab_ai_copilot_lg.py â€” Tab: AI Copilot (LangGraph Version) - Enhanced UI

å¢å¼ºç‰¹æ€§:
    1. å®æ—¶èŠ‚ç‚¹è¿½è¸ª: st.status åŠ¨æ€æ˜¾ç¤ºå½“å‰æ‰§è¡ŒèŠ‚ç‚¹
    2. å®¡è®¡å¤±è´¥é«˜äº®: çº¢è‰²/é»„è‰²è­¦ç¤º + è‡ªåŠ¨ä¿®æ­£æç¤º
    3. å·¥å…·è°ƒç”¨é€æ˜åŒ–: æ˜¾ç¤ºå‡½æ•°åã€å‚æ•°ã€è¿”å›å€¼

å¯¹å¤–æš´éœ²: render(ctx)
"""

import streamlit as st
import time
from ui_components import COLORS, render_section_header

from agent_logic_lg import (
    run_agent_stream,
    build_system_prompt,
    ThinkingStep,
    COMPLIANCE_LIMITS,
)


# ============================================================
# èŠ‚ç‚¹çŠ¶æ€æ¶ˆæ¯æ˜ å°„
# ============================================================
NODE_STATUS_MESSAGES = {
    "analyze": ("ğŸ”", "Analyzing risk intent...", "Intent Analysis"),
    "calculate": ("âš™ï¸", "Calling Risk Engine...", "Risk Calculation"),
    "audit": ("ğŸ›¡ï¸", "Running compliance audit...", "Compliance Audit"),
    "refine": ("ğŸ”„", "Compliance risk detected! Auto-correcting...", "Auto Refinement"),
    "respond": ("ğŸ’¬", "Generating response...", "Response Generation"),
}


# ============================================================
# é¢„è®¾é—®é¢˜
# ============================================================
QUICK_QUESTIONS = {
    "ğŸ“Š Summary": "Give me a summary of our current risk position.",
    "âš ï¸ Limits": "Check all risk limits and highlight any breaches.",
    "ğŸšï¸ Stress": "Run a stress test with rates up 100bp and equity down 15%.",
    "ğŸ›¡ï¸ Hedge 85%": "I want to increase our duration hedge ratio to 85%.",
    "ğŸ“ˆ Rates": "Which assets are most sensitive to interest rate changes?",
}


# ============================================================
# ä¸»æ¸²æŸ“å‡½æ•°
# ============================================================

def render(ctx: dict):
    """Tab ä¸»å…¥å£ - LangGraph å¢å¼ºç‰ˆ"""
    
    # â”€â”€ Beta æ ‡ç­¾ â”€â”€
    st.markdown(
        f"""
        <div style="
            background: linear-gradient(90deg, {COLORS['accent']}20, transparent);
            border-left: 3px solid {COLORS['accent']};
            padding: 12px 16px;
            border-radius: 0 8px 8px 0;
            margin-bottom: 16px;
            display: flex;
            align-items: center;
            gap: 12px;
        ">
            <span style="
                background-color: {COLORS['accent']};
                color: white;
                padding: 2px 8px;
                border-radius: 4px;
                font-size: 0.7rem;
                font-weight: 700;
            ">BETA</span>
            <span style="color: {COLORS['text_secondary']}; font-size: 0.85rem;">
                <strong>LangGraph Engine</strong> â€” Real-time node tracking with tool-use transparency
            </span>
        </div>
        """,
        unsafe_allow_html=True,
    )
    
    # â”€â”€ åˆå§‹åŒ– Session State â”€â”€
    if 'lg_chat_history' not in st.session_state:
        st.session_state.lg_chat_history = []
    if 'lg_thinking_steps' not in st.session_state:
        st.session_state.lg_thinking_steps = []

    # â”€â”€ æ£€æŸ¥ API Key â”€â”€
    api_key = _get_api_key()
    system_prompt = build_system_prompt(ctx)

    # â”€â”€ å¸ƒå±€ â”€â”€
    col_main, col_thinking = st.columns([2, 1])
    
    with col_main:
        _render_status_summary(ctx)
        st.markdown("<div style='height: 16px;'></div>", unsafe_allow_html=True)
        
        _render_quick_questions(api_key, system_prompt, ctx)
        st.markdown("<div style='height: 16px;'></div>", unsafe_allow_html=True)
        
        _render_chat_section(api_key, system_prompt, ctx)
    
    with col_thinking:
        _render_thinking_panel()


# ============================================================
# UI ç»„ä»¶: çŠ¶æ€æ‘˜è¦
# ============================================================

def _render_status_summary(ctx: dict):
    """æ¸²æŸ“é£é™©çŠ¶æ€æ‘˜è¦"""
    render_section_header("Portfolio Status", "ğŸ“‹")
    
    funded_status = ctx['funded_status']
    surplus = ctx['surplus']
    fx_pct = ctx['fx_pct']
    duration_gap = ctx['asset_dur'] - ctx['liability_dur']
    
    limits_df = ctx['limits_df']
    breaches = len(limits_df[limits_df['Status'].str.contains('BREACH', na=False)])
    warnings = len(limits_df[limits_df['Status'].str.contains('WARN', na=False)])

    if breaches > 0:
        status_icon, status_text, status_color = "ğŸ”´", f"{breaches} BREACH", COLORS['negative']
    elif warnings > 0:
        status_icon, status_text, status_color = "ğŸŸ¡", f"{warnings} WARNING", COLORS['warning']
    else:
        status_icon, status_text, status_color = "ğŸŸ¢", "ALL OK", COLORS['positive']

    st.markdown(
        f"""
        <div style="
            background-color: {COLORS['bg_card']};
            border: 1px solid {COLORS['bg_border']};
            border-radius: 8px;
            padding: 16px;
        ">
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 12px;">
                <span style="font-weight: 600; color: {COLORS['text_primary']};">Risk Dashboard</span>
                <span style="
                    background-color: {status_color}20;
                    color: {status_color};
                    padding: 4px 12px;
                    border-radius: 16px;
                    font-size: 0.8rem;
                    font-weight: 600;
                ">{status_icon} {status_text}</span>
            </div>
            <div style="display: grid; grid-template-columns: repeat(4, 1fr); gap: 12px;">
                <div style="text-align: center;">
                    <div style="color: {COLORS['text_tertiary']}; font-size: 0.75rem;">Funded</div>
                    <div style="color: {COLORS['positive']}; font-size: 1.1rem; font-weight: 600;">{funded_status:.1%}</div>
                </div>
                <div style="text-align: center;">
                    <div style="color: {COLORS['text_tertiary']}; font-size: 0.75rem;">Surplus</div>
                    <div style="color: {COLORS['text_primary']}; font-size: 1.1rem; font-weight: 600;">${surplus/1000:.1f}B</div>
                </div>
                <div style="text-align: center;">
                    <div style="color: {COLORS['text_tertiary']}; font-size: 0.75rem;">Duration Gap</div>
                    <div style="color: {COLORS['text_primary']}; font-size: 1.1rem; font-weight: 600;">{duration_gap:.1f} yrs</div>
                </div>
                <div style="text-align: center;">
                    <div style="color: {COLORS['text_tertiary']}; font-size: 0.75rem;">FX Exp</div>
                    <div style="color: {COLORS['warning'] if fx_pct > 0.12 else COLORS['text_primary']}; font-size: 1.1rem; font-weight: 600;">{fx_pct:.1%}</div>
                </div>
            </div>
        </div>
        """,
        unsafe_allow_html=True,
    )


# ============================================================
# UI ç»„ä»¶: å¿«é€Ÿé—®é¢˜
# ============================================================

def _render_quick_questions(api_key: str, system_prompt: str, ctx: dict):
    """æ¸²æŸ“å¿«é€Ÿé—®é¢˜æŒ‰é’®"""
    render_section_header("Quick Actions", "âš¡")
    
    cols = st.columns(5)
    
    for i, (label, question) in enumerate(QUICK_QUESTIONS.items()):
        with cols[i]:
            if st.button(label, use_container_width=True, disabled=not api_key, key=f"lg_quick_{i}"):
                _process_user_input_with_status(question, system_prompt, ctx, api_key)


# ============================================================
# UI ç»„ä»¶: èŠå¤©åŒºåŸŸ
# ============================================================

def _render_chat_section(api_key: str, system_prompt: str, ctx: dict):
    """æ¸²æŸ“èŠå¤©åŒºåŸŸ"""
    render_section_header("Conversation", "ğŸ’¬")
    
    chat_container = st.container(height=280)
    with chat_container:
        if not st.session_state.lg_chat_history:
            st.markdown(
                f"""
                <div style="color: {COLORS['text_tertiary']}; text-align: center; padding: 30px 20px;">
                    <p style="font-size: 1rem; margin-bottom: 8px;">ğŸ§ª LangGraph AI Risk Advisor</p>
                    <p style="font-size: 0.85rem;">Watch real-time node execution in the Thinking Panel â†’</p>
                    <p style="font-size: 0.8rem; color: {COLORS['accent']}; margin-top: 12px;">
                        ğŸ’¡ Try "Hedge 85%" to see the Audit Loop in action!
                    </p>
                </div>
                """,
                unsafe_allow_html=True,
            )
        else:
            for message in st.session_state.lg_chat_history:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
    
    if not api_key:
        st.warning("âš ï¸ OpenAI API key not configured.")
        st.chat_input("Type your question...", disabled=True)
        return

    col_input, col_clear = st.columns([6, 1])
    
    with col_clear:
        if st.button("ğŸ—‘ï¸", use_container_width=True, help="Clear", key="lg_clear"):
            st.session_state.lg_chat_history = []
            st.session_state.lg_thinking_steps = []
            st.rerun()

    user_input = st.chat_input("Ask about risk, stress tests, or hedging...", key="lg_input")

    if user_input:
        _process_user_input_with_status(user_input, system_prompt, ctx, api_key)


# ============================================================
# UI ç»„ä»¶: æ€è€ƒé¢æ¿ (å¢å¼ºç‰ˆ)
# ============================================================

def _render_thinking_panel():
    """æ¸²æŸ“æ€è€ƒè¿‡ç¨‹é¢æ¿ - å¢å¼ºç‰ˆ"""
    st.markdown(
        f"""
        <div style="
            background-color: {COLORS['bg_card']};
            border: 1px solid {COLORS['bg_border']};
            border-radius: 8px;
            padding: 16px;
            min-height: 450px;
        ">
            <div style="
                display: flex;
                justify-content: space-between;
                align-items: center;
                margin-bottom: 16px;
                padding-bottom: 12px;
                border-bottom: 1px solid {COLORS['bg_border']};
            ">
                <span style="font-size: 0.95rem; font-weight: 600; color: {COLORS['text_primary']};">
                    ğŸ§  LangGraph Execution
                </span>
                <span style="
                    font-size: 0.7rem;
                    color: {COLORS['accent']};
                    background-color: {COLORS['accent']}15;
                    padding: 2px 8px;
                    border-radius: 4px;
                ">StateGraph</span>
            </div>
        """,
        unsafe_allow_html=True,
    )
    
    if not st.session_state.lg_thinking_steps:
        st.markdown(
            f"""
            <div style="color: {COLORS['text_tertiary']}; font-size: 0.85rem; padding: 20px;">
                <p style="margin-bottom: 16px; text-align: center;">Waiting for execution...</p>
                <div style="font-size: 0.75rem; line-height: 2;">
                    <p>ğŸ” <code>analyze</code> â†’ Intent detection</p>
                    <p>âš™ï¸ <code>calculate</code> â†’ Risk engine</p>
                    <p>ğŸ›¡ï¸ <code>audit</code> â†’ Compliance check</p>
                    <p>ğŸ”„ <code>refine</code> â†’ Auto-correction</p>
                    <p>ğŸ’¬ <code>respond</code> â†’ LLM response</p>
                </div>
            </div>
            """,
            unsafe_allow_html=True,
        )
    else:
        for step in st.session_state.lg_thinking_steps:
            _render_thinking_step_enhanced(step)
    
    st.markdown("</div>", unsafe_allow_html=True)


def _render_thinking_step_enhanced(step: ThinkingStep):
    """æ¸²æŸ“å•ä¸ªæ€è€ƒæ­¥éª¤ - å¢å¼ºç‰ˆ (å«å·¥å…·è°ƒç”¨ä¿¡æ¯)"""
    
    # çŠ¶æ€é…ç½®
    status_config = {
        "running": {"icon": "â³", "color": COLORS['warning'], "bg": f"{COLORS['warning']}10", "border": COLORS['warning']},
        "success": {"icon": "âœ…", "color": COLORS['positive'], "bg": f"{COLORS['positive']}10", "border": COLORS['positive']},
        "warning": {"icon": "âš ï¸", "color": "#ff6b6b", "bg": "#ff6b6b15", "border": "#ff6b6b"},
        "error": {"icon": "âŒ", "color": COLORS['negative'], "bg": f"{COLORS['negative']}10", "border": COLORS['negative']},
    }
    
    config = status_config.get(step.status, status_config["running"])
    
    # ç‰¹æ®Šå¤„ç†: å®¡è®¡å¤±è´¥é«˜äº®
    if step.is_warning:
        config = {
            "icon": "ğŸš¨",
            "color": "#ff4757",
            "bg": "#ff475720",
            "border": "#ff4757",
        }
    
    # æ„å»º HTML
    tool_info_html = ""
    if step.tool_call:
        tool_info_html += f"""
        <div style="
            margin-top: 8px;
            padding: 8px;
            background-color: {COLORS['bg_hover']};
            border-radius: 4px;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.7rem;
        ">
            <div style="color: {COLORS['accent']};">ğŸ“¦ {step.tool_call}</div>
        """
        if step.tool_params:
            tool_info_html += f"""<div style="color: {COLORS['text_tertiary']}; margin-top: 2px;">â”œâ”€ params: {step.tool_params}</div>"""
        if step.tool_result:
            tool_info_html += f"""<div style="color: {COLORS['positive']}; margin-top: 2px;">â””â”€ result: {step.tool_result}</div>"""
        tool_info_html += "</div>"
    
    detail_html = ""
    if step.detail:
        detail_html = f"<div style='font-size: 0.75rem; color: {COLORS['text_tertiary']}; margin-top: 4px;'>{step.detail}</div>"
    
    st.markdown(
        f"""
        <div style="
            background-color: {config['bg']};
            border-left: 3px solid {config['border']};
            border-radius: 4px;
            padding: 12px;
            margin-bottom: 10px;
        ">
            <div style="display: flex; align-items: center; gap: 8px;">
                <span style="font-size: 1rem;">{config['icon']}</span>
                <span style="font-size: 0.85rem; font-weight: 600; color: {COLORS['text_primary']};">{step.node}</span>
            </div>
            <div style="font-size: 0.8rem; color: {config['color']}; margin-top: 4px; font-weight: 500;">
                {step.message}
            </div>
            {detail_html}
            {tool_info_html}
        </div>
        """,
        unsafe_allow_html=True,
    )


# ============================================================
# æ ¸å¿ƒå¤„ç†å‡½æ•° - å®æ—¶çŠ¶æ€è¿½è¸ªç‰ˆ
# ============================================================

def _process_user_input_with_status(user_input: str, system_prompt: str, ctx: dict, api_key: str):
    """
    å¤„ç†ç”¨æˆ·è¾“å…¥ - ä½¿ç”¨ st.status å®æ—¶è¿½è¸ª
    
    å…³é”®ç‰¹æ€§:
    - st.status æ˜¾ç¤ºå½“å‰èŠ‚ç‚¹
    - æµå¼æ›´æ–°æ€è€ƒæ­¥éª¤
    - å®¡è®¡å¤±è´¥ç‰¹æ®Šå¤„ç†
    """
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.lg_chat_history.append({"role": "user", "content": user_input})
    st.session_state.lg_thinking_steps = []
    
    # åˆ›å»ºçŠ¶æ€å®¹å™¨
    status_placeholder = st.empty()
    
    try:
        with status_placeholder.status("ğŸ§  LangGraph Engine running...", expanded=True) as status:
            final_response = ""
            
            for node_name, state, is_final in run_agent_stream(
                user_query=user_input,
                ctx=ctx,
                system_prompt=system_prompt,
                api_key=api_key,
            ):
                # è·å–èŠ‚ç‚¹ä¿¡æ¯
                icon, message, label = NODE_STATUS_MESSAGES.get(
                    node_name, 
                    ("ğŸ”„", "Processing...", node_name)
                )
                
                # æ›´æ–°çŠ¶æ€æ˜¾ç¤º
                status.update(label=f"{icon} {message}")
                
                # å†™å…¥å½“å‰èŠ‚ç‚¹æ‰§è¡Œä¿¡æ¯
                st.write(f"**Node:** `{node_name}` â€” {label}")
                
                # æ£€æŸ¥æ˜¯å¦å®¡è®¡å¤±è´¥
                audit_result = state.get("audit_result", {})
                if node_name == "audit" and audit_result.get("status") == "FAIL":
                    st.warning("ğŸš¨ **Compliance Failed!** Auto-correcting...")
                
                # æ”¶é›†æ€è€ƒæ­¥éª¤
                if "thinking_steps" in state:
                    st.session_state.lg_thinking_steps = state["thinking_steps"]
                
                # æ”¶é›†æœ€ç»ˆå“åº”
                if is_final and state.get("final_response"):
                    final_response = state["final_response"]
                
                # çŸ­æš‚å»¶è¿Ÿè®©ç”¨æˆ·èƒ½çœ‹åˆ°çŠ¶æ€å˜åŒ–
                time.sleep(0.1)
            
            # å®ŒæˆçŠ¶æ€
            status.update(label="âœ… Complete", state="complete", expanded=False)
        
        # æ·»åŠ åŠ©æ‰‹å“åº”
        st.session_state.lg_chat_history.append({
            "role": "assistant",
            "content": final_response or "Unable to generate response",
        })
        
        # åˆ·æ–°é¡µé¢æ˜¾ç¤ºç»“æœ
        st.rerun()

    except Exception as e:
        status_placeholder.empty()
        st.session_state.lg_thinking_steps.append(ThinkingStep(
            node="âŒ Error",
            status="error",
            message=str(e),
        ))
        st.session_state.lg_chat_history.append({
            "role": "assistant",
            "content": f"Error: {str(e)}",
        })
        st.rerun()


# ============================================================
# è¾…åŠ©å‡½æ•°
# ============================================================

def _get_api_key() -> str:
    try:
        return st.secrets.get("OPENAI_API_KEY", "")
    except:
        return ""